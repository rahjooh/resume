<html>
	<head>
		<link href="style.css" rel="stylesheet">
		<title>Hadi Rahjou resume</title>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
	</head>

	<body>
		<header id="header">
			<!-- resume header with your name and title -->
			<h1><b>Hadi</b> Rahjou</h1>
			<hr>
			Data Engineer 
			<hr>
		</header>
		<main>
			<article id="mainLeft">
				<section>
					<h2>CONTACT</h2>
					<!-- contact info including social media -->
                    <p>
                        <i class="fa fa-envelope" aria-hidden="true"></i>
                        <a href="mailto:rahjooh@gmail.com">rahjooh@gmail.com</a>
                    </p>
                    <p>
                        <i class="fab fa-github" aria-hidden="true"></i>
                        <a href="https://github.com/rahjooh">rahjooh</a>
                    </p>
                    <p>
                        <i class="fab fa-linkedin" aria-hidden="true"></i>
                        <a href="https://linkedin.com/in/hadirahjou/">Hadi Rahjou</a>
                    </p>
                    <p>
                        <i class="fa fa-phone" aria-hidden="true"></i>
                        <a>+98 912 678 0 521</a>
                    </p>
				</section>
				<section>
					<h2>SKILLS</h2>
					<!-- your skills AKA "buzzwords" -->
                    <p> <li> Apache Hadoop </li>
                        <li>Apache Spark  </li>
                        <li>Apache Kafka  </li>
                        <li>Apache Airflow  </li>
                        <li>AWS </li>
                        <li>Azure </li>
                        <li>GCP </li>
                        <li>Terraform </li>
                        <li>Snowflake </li>
                        <li>docker </li>
                        <li>Python </li>
                        <li>django </li>
                        <li>Java</li>
                        <li>Sqlserver </li>
                        <li>Postgres</li>
                        <li>git </li>
                        <li>linux</li>
                    </p>
				</section>
				<section>
					<h2>EDUCATION</h2>
					<!-- your education -->
                    <b>Computer Sciense</b>
                    <p>  
                        <a href="url">Tehran University</a>
                    </p>
                    <p>
                        2016-2018
                    </p>
					
		    <b>Software Engineering</b>
                    <p>  
                        <a href="url">Azad Islamic University of Yazd</a>
                    </p>
                    <p>
                        2002-2006
                    </p>
				</section>            
			</article>


			<article id="mainRight">
				<section>
					<h2>ABOUT</h2>
					<!-- about you -->
					<p>Data Engineer with 12 years of experience in DDD, TDD, Python, Apache Spark, Spark SQL, Spark Mllib, Kafka, MS SQL, PostgreSQL, ETL, Data 
                        Pipeline, Machine Learning, Data Analysis, Data Visualization and Data Engineering , who always seek the new challenges, knowledge and opportunities.</p>
				</section>


				<section>
					<h2>WORK EXPERIENCE</h2>
					<!-- your work experience -->
                    <h3><b>JOB TITLE</b></h3>

                    <p>
                        <b><a href="https://isc.co.ir/">Informatics Services Corporation </a></b> |March 2022 - Now
                    </p>
                    <ul class="roman">
                        <p>
                            <li><b>Data </b>: Boosting Data pipelines to build and maintain the ETL and ELT more than 90 Linux servers sum-up >100 million transactions daily on cloud. 
                                • Developing Python modules using async features running concurrently over servers using parallel and multiprocessing features achieving 
                                80% faster reporting & running checklists. </li>
                        </p>
                        <ul class="square">
                                <li>Orchestrating lightweight MicroServices over Gateway layer with Python and Django Rest Framework and serving transactions of 15 biggest 
                                    banks of the country </li>
                                <li>Developed on AWS resolve 100% of issues on messaging, filtering, audit, authorizing, performance, maintenance provide Middleware as 
                                    transparent REST API </li>
                                <li> Develop MySQL database; create complex pivots-aggregate , saved an estimated 60% of querying time effective compare with old fashion styles </li>
                                <li>Implementing a database management dashboard via DjangoRest Framework and monitoring board for all databases</li>
                        </ul>
                    </ul>

                    <p>
                        <b><a href="https://soshyant.co/">Soshyant </a></b> |  Feb 2022 – Feb 2023 (part time)
                    </p>
                    <ul class="roman">
                        <p>
                            <li><b>Portfolio </b>: Create a service for portfolio of the traders of the stock. That gain is result of some complicated aggregations over data with  billions of records. </li>
                        </p>
                        <ul class="square">
                                <li>Create an Spark cluster on VDIs </li>
                                <li>Implemention  pyspark application to calc portfolio and store in hadoop and Sql</li>
                                <li>Maintain result's database for providing service to traders</li>
                                <li>Implementation of portfolio service to serve on Kafka and Rest api via springboot</li>
                        </ul>
                    </ul>



                    <p>
                        <b><a href="https://ba24.ir/">Ayandeh Bank </a> </b>| May 2017 - Jan 2022
                    </p>
                    <ul class="roman">
                        <li><b>Customer 360 Dashboard </b>: a dashboard to have all account information ,statistical reports and analytical feedback in a single page. was a huge data project. </li>
                        <ul class="square">
                         <li>Fetching historical data from different sources into the hadoop cluster</li>
                         <li>Writing a daily fetcher for daily data over 16 different resources</li>
                         <li>Implementaion of Customer 360 on pyspark</li>
                         <li>Stage daily results in a postgres for serving the 360 tablue dashboard</li>
                        </ul><br>


                        <li><b>Customer Segmentation</b> : a bigdata project which segments customers over RFM model and customized kmeans clustering algorithm to serve bank's apps and campaigns</li>
                        <ul class="square">
                            <li>Build and maintain a Hadoop cluster</li>
                            <li>Build and maintain a Spark cluster</li>
                            <li>Huge research and r&d Implementaion for choose methods of Segmentation : clustering algorithms ,number of clusters ,financial models</li>
                            <li>Implementaion customized kmeans to have a domain close segments</li>
                            <li>Stage daily results on Sqlserver</li>
                        </ul><br>


                        <li><b>Churn Detection</b> : a bigdata dashboard to detect and predict churn of the customers </li>
                        <ul class="square">
                            <li>Stage all transactional data of customers into hdfs</li>
                            <li>Calc monetary rate , frequency rate and recency rate of each segment base on average of customers and stock behaviors.</li>
                            <li>Calc expected monetary and frequency of each customer base on his segment's rates via pyspark</li>
                            
                            <li>Detect churned customer for serving the tableau dashboard</li>
                            <li>Predict the customers with the risk of churn by Logestic Regression algorithm over spark</li>
                        </ul><br>

                        <li><b>I/O Bank Resources</b> : an statistical dashboard to reports all mounetry that bank recieved and spent among all it's ports. It is a managment dashboard and managers of the bank are it's users.</li>
                        <ul class="square">
                            <li>create a java job to feed resources table from several resources</li>
                            <li>Implementaion of high complex aggregations to gain a daily, monthly and yearly result</li>
                            <li>create an application web server via django and plotly for automate report publishing</li>
                            <li>implementng access managing for hierarchical access of users</li>
                        </ul><br>

                        <li><b>DBA Assistant</b> : experienced as a backup database admin of Ayandeh bank.</li>
                        <ul class="square">
                            <li>Implementing a FTP Listener by python to catch and report lateness or lackness of routine files</li>
                            <li>Controlling SQL Packages stats</li>
                            <li>Create and schedule backup of database and perform a seasonly backup manouvre.</li>
                            <li>Complex Querying in case of bank reconciliation</li>
                        </ul><br>

                       </ul>


                    <p>
                        <b><a href="https://pedec.ir/">PEDEC </a></b> | Apr 2012 - Apr 2017
                    </p>
                    <ul class="roman">
                        <p>
                            <li><b>Oil data unification </b>: Convert and unify data from multiple sources</li>
                        </p>
                        <ul class="square">
                                <li>Implementing Convert project to unify all excel, access, foxpro, txt, xml .. files into Oracledb</li>
                                <li>Create PEDEC data policy to maintain all new data is generated in a usable form</li>
                                <li>Design and Implementaion Oracledb cluster and run CDC on Golden Gate tools</li>
                                <li>Design and Support PEDEC data ticketing webtools via java spring </li>
                                <li>Maintain all needs of PEDEC db such as routine backup , grant administration, .. </li>
                        </ul>
                    </ul>
				</section>
			</article>
		</main>
	</body>
</html>
